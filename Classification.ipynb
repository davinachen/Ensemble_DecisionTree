{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(y, ml_task):\n",
    "    \n",
    "    if ml_task == \"regression\":\n",
    "        leaf = float(np.mean(y))\n",
    "    else:\n",
    "        counts = y.value_counts().reset_index()\n",
    "        leaf = counts.iloc[0,0]\n",
    "    \n",
    "    return leaf\n",
    "\n",
    "\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    X = data.drop(columns='target')\n",
    "    potential_splits = {}\n",
    "    columns = X.columns.tolist()\n",
    "    for column in columns:\n",
    "\n",
    "        values = X[[column]]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column] = unique_values - 1\n",
    "    \n",
    "    return potential_splits\n",
    "\n",
    "\n",
    "def calculate_gini(y):\n",
    "    \n",
    "    counts = y.value_counts().to_numpy()\n",
    "    probabilities = counts / counts.sum()\n",
    "    gini = np.sum(probabilities*(1-probabilities))\n",
    "     \n",
    "    return gini\n",
    "\n",
    "\n",
    "def calculate_mse(y):\n",
    "    \n",
    "    if len(y) == 0:\n",
    "        mse = 0\n",
    "    else:\n",
    "        mse = np.mean((y - np.mean(y)) **2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "\n",
    "def total_impurity(data_left, data_right, metric_function):\\\n",
    "\n",
    "    n = len(data_left) + len(data_right)\n",
    "    prop_left = len(data_left) / n\n",
    "    prop_right = len(data_right) / n\n",
    "\n",
    "    overall_metric =  (prop_left * metric_function(data_left['target']) \n",
    "                     + prop_right * metric_function(data_right['target']))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "def split_data(data, column_types, split_column, split_value):\n",
    "    \n",
    "    type_of_feature = column_types[split_column]\n",
    "\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_left = data[data[split_column] <= split_value]\n",
    "        data_right = data[data[split_column] >  split_value]\n",
    "    \n",
    "    else:\n",
    "        data_left = data[data[split_column] == split_value]\n",
    "        data_right = data[data[split_column] != split_value]\n",
    "    \n",
    "    return data_left, data_right\n",
    "\n",
    "\n",
    "def determine_best_split(data, column_types, potential_splits, ml_task):\n",
    "\n",
    "    best_overall_metric = np.inf\n",
    "    for column, splits in potential_splits.items():\n",
    "        for split in splits:\n",
    "            \n",
    "            data_left, data_right = split_data(data, column_types, split_column=column, split_value=split)\n",
    "            \n",
    "            if ml_task == \"regression\":\n",
    "                node_impurity = total_impurity(data_left, data_right, metric_function=calculate_mse)\n",
    "            else:\n",
    "                node_impurity = total_impurity(data_left, data_right, metric_function=calculate_gini)\n",
    "            \n",
    "            if node_impurity <= best_overall_metric:\n",
    "                best_overall_metric = node_impurity\n",
    "                best_split_column = column\n",
    "                best_split_value = split\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, column_types, ml_task, min_samples=2, max_depth=5):\n",
    "    \n",
    "    leaves = []\n",
    "    path = 'root'\n",
    "    datasets = [(df,path)]\n",
    "    split_conditions = []\n",
    "    for current_depth in range(max_depth+1):\n",
    "        next_set = []\n",
    "        for dataset in datasets:\n",
    "            data = dataset[0]\n",
    "            path = dataset[1]\n",
    "            \n",
    "            if (len(data.target.unique()) == 1) or (len(data) < min_samples):\n",
    "                leaf = create_leaf(data[['target']], ml_task)\n",
    "                leaves.append((path,leaf))\n",
    "                continue\n",
    "\n",
    "            potential_splits = get_potential_splits(data)\n",
    "            split_column, split_value = determine_best_split(data, column_types, potential_splits, ml_task)\n",
    "            data_left, data_right = split_data(data, column_types, split_column, split_value)\n",
    "\n",
    "            if len(data_left) == 0 or len(data_right) == 0:\n",
    "                leaf = create_leaf(data[['target']], ml_task)\n",
    "                leaves.append((path,leaf))\n",
    "                continue\n",
    "            print(len(data_left),len(data_right))\n",
    "            split_conditions.append((path,split_column,split_value))\n",
    "            next_set.append((data_left,path+',l'))\n",
    "            next_set.append((data_right,path+',r'))\n",
    "\n",
    "        datasets = next_set\n",
    "\n",
    "    for dataset in datasets:\n",
    "        data = dataset[0]\n",
    "        path = dataset[1]\n",
    "        leaf = create_leaf(data[['target']], ml_task)\n",
    "        leaves.append((path,leaf))\n",
    "\n",
    "    return leaves, split_conditions\n",
    "\n",
    "# Make predictions with decision tree\n",
    "\n",
    "def make_predictions(df, column_types, leaves, split_conditions):\n",
    "\n",
    "    df['path'] = 'root'\n",
    "    df['value'] = 0\n",
    "    \n",
    "    for split_condition in split_conditions:\n",
    "        path = split_condition[0]\n",
    "        column = split_condition[1]\n",
    "        value = split_condition[2]\n",
    "\n",
    "        if column_types[column] == \"continuous\":\n",
    "            df.loc[(df['path']==path)&(df[column]<= value),'path'] = path+',l'\n",
    "            df.loc[(df['path']==path)&(df[column]> value),'path'] = path+',r'\n",
    "        else:\n",
    "            df.loc[(df['path']==path)&(df[column] == value),'path'] = path+',l'\n",
    "            df.loc[(df['path']==path)&(df[column]!= value),'path'] = path+',r'\n",
    "\n",
    "    df['prediction'] = df['path'].map(dict(leaves))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_accuracy(df, column_types, ml_task, leaves, split_conditions):\n",
    "    predictions = make_predictions(df, column_types, leaves, split_conditions).prediction\n",
    "    \n",
    "    if ml_task == 'regression':    \n",
    "        predictions_array = predictions.values\n",
    "        target_array = df.target.values\n",
    "        metric = np.sqrt(sum((predictions_array - target_array)**2) / len(predictions_array))\n",
    "        \n",
    "    else:\n",
    "        predictions_correct = predictions == df.target\n",
    "        metric = predictions_correct.mean()\n",
    "    \n",
    "    return  metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read csvs\n",
    "train_df = pd.read_csv('500_Person_Gender_Height_Weight_Index.csv')\n",
    "\n",
    "# Filling  NA\n",
    "train_df = train_df.fillna(0)\n",
    "train_df = train_df.rename(columns={'Index':'target'})\n",
    "\n",
    "# categorical variable encoding\n",
    "labelencoder = LabelEncoder()\n",
    "train_df['Gender'] = labelencoder.fit_transform(train_df['Gender'])\n",
    "\n",
    "# train-test split\n",
    "train, test = train_test_split(train_df, test_size = 0.2, random_state=50)\n",
    "column_types = {'Gender':'categorical','Height':'continuous','Weight':'continuous'}\n",
    "ml_task = 'classifier'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 144\n",
      "118 138\n",
      "116 28\n",
      "53 65\n",
      "52 86\n",
      "94 22\n",
      "13 15\n",
      "20 33\n",
      "37 28\n",
      "20 32\n",
      "45 41\n",
      "7 15\n",
      "12 3\n",
      "7 13\n",
      "3 30\n",
      "13 24\n",
      "3 25\n",
      "15 5\n",
      "28 4\n",
      "9 36\n",
      "33 8\n",
      "3 4\n",
      "9 3\n",
      "3 4\n",
      "10 3\n",
      "19 11\n",
      "4 9\n",
      "7 17\n",
      "19 6\n",
      "8 7\n",
      "1 3\n",
      "4 5\n",
      "31 5\n",
      "7 26\n",
      "3 1\n",
      "7 2\n",
      "1 2\n",
      "1 2\n",
      "11 8\n",
      "9 2\n",
      "7 10\n",
      "3 16\n",
      "5 1\n",
      "4 3\n",
      "2 2\n",
      "5 26\n",
      "2 3\n",
      "4 3\n",
      "18 8\n",
      "2 1\n",
      "4 3\n"
     ]
    }
   ],
   "source": [
    "leaves, split_conditions = decision_tree_algorithm(train, column_types, ml_task, min_samples=2, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root,r,l,l': 5,\n",
       " 'root,r,r,l': 4,\n",
       " 'root,r,l,r,r': 5,\n",
       " 'root,r,r,r,r': 4,\n",
       " 'root,l,l,l,r,l': 5,\n",
       " 'root,l,l,r,r,l': 3,\n",
       " 'root,l,r,l,l,r': 4,\n",
       " 'root,l,r,l,r,l': 5,\n",
       " 'root,l,r,r,r,r': 4,\n",
       " 'root,r,l,r,l,l': 4,\n",
       " 'root,r,r,r,l,r': 5,\n",
       " 'root,l,l,l,l,l,r': 3,\n",
       " 'root,l,l,l,l,r,l': 2,\n",
       " 'root,l,l,r,l,l,l': 1,\n",
       " 'root,l,l,r,l,l,r': 0,\n",
       " 'root,l,l,r,l,r,l': 2,\n",
       " 'root,l,r,l,l,l,l': 5,\n",
       " 'root,l,r,l,r,r,l': 4,\n",
       " 'root,l,r,l,r,r,r': 5,\n",
       " 'root,l,r,r,l,l,r': 3,\n",
       " 'root,r,l,r,l,r,r': 4,\n",
       " 'root,r,r,r,l,l,r': 4,\n",
       " 'root,l,l,l,l,l,l,l': 3,\n",
       " 'root,l,l,l,l,l,l,r': 2,\n",
       " 'root,l,l,l,l,r,r,l': 0,\n",
       " 'root,l,l,l,l,r,r,r': 2,\n",
       " 'root,l,l,l,r,r,l,l': 4,\n",
       " 'root,l,l,l,r,r,l,r': 4,\n",
       " 'root,l,l,l,r,r,r,l': 3,\n",
       " 'root,l,l,l,r,r,r,r': 4,\n",
       " 'root,l,l,r,l,r,r,l': 1,\n",
       " 'root,l,l,r,l,r,r,r': 1,\n",
       " 'root,l,l,r,r,r,l,l': 2,\n",
       " 'root,l,l,r,r,r,l,r': 2,\n",
       " 'root,l,l,r,r,r,r,l': 3,\n",
       " 'root,l,l,r,r,r,r,r': 2,\n",
       " 'root,l,r,l,l,l,r,l': 4,\n",
       " 'root,l,r,l,l,l,r,r': 5,\n",
       " 'root,l,r,r,l,l,l,l': 4,\n",
       " 'root,l,r,r,l,l,l,r': 2,\n",
       " 'root,l,r,r,l,r,l,l': 4,\n",
       " 'root,l,r,r,l,r,l,r': 4,\n",
       " 'root,l,r,r,l,r,r,l': 5,\n",
       " 'root,l,r,r,l,r,r,r': 4,\n",
       " 'root,l,r,r,r,l,l,l': 3,\n",
       " 'root,l,r,r,r,l,l,r': 2,\n",
       " 'root,l,r,r,r,l,r,l': 3,\n",
       " 'root,l,r,r,r,l,r,r': 3,\n",
       " 'root,r,l,r,l,r,l,l': 4,\n",
       " 'root,r,l,r,l,r,l,r': 5,\n",
       " 'root,r,r,r,l,l,l,l': 5,\n",
       " 'root,r,r,r,l,l,l,r': 4}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('root', 'Weight', 122),\n",
       " ('root,l', 'Weight', 84),\n",
       " ('root,r', 'Height', 185),\n",
       " ('root,l,l', 'Height', 166),\n",
       " ('root,l,r', 'Height', 164),\n",
       " ('root,r,l', 'Height', 178),\n",
       " ('root,r,r', 'Weight', 139),\n",
       " ('root,l,l,l', 'Weight', 65),\n",
       " ('root,l,l,r', 'Weight', 69),\n",
       " ('root,l,r,l', 'Weight', 97),\n",
       " ('root,l,r,r', 'Height', 181),\n",
       " ('root,r,l,r', 'Weight', 139),\n",
       " ('root,r,r,r', 'Height', 196),\n",
       " ('root,l,l,l,l', 'Height', 152),\n",
       " ('root,l,l,l,r', 'Height', 141),\n",
       " ('root,l,l,r,l', 'Weight', 55),\n",
       " ('root,l,l,r,r', 'Height', 172),\n",
       " ('root,l,r,l,l', 'Height', 155),\n",
       " ('root,l,r,l,r', 'Height', 160),\n",
       " ('root,l,r,r,l', 'Weight', 95),\n",
       " ('root,l,r,r,r', 'Weight', 114),\n",
       " ('root,r,l,r,l', 'Weight', 129),\n",
       " ('root,r,r,r,l', 'Weight', 150),\n",
       " ('root,l,l,l,l,l', 'Weight', 59),\n",
       " ('root,l,l,l,l,r', 'Height', 162),\n",
       " ('root,l,l,l,r,r', 'Height', 160),\n",
       " ('root,l,l,r,l,l', 'Height', 180),\n",
       " ('root,l,l,r,l,r', 'Height', 178),\n",
       " ('root,l,l,r,r,r', 'Weight', 82),\n",
       " ('root,l,r,l,l,l', 'Height', 145),\n",
       " ('root,l,r,l,r,r', 'Weight', 109),\n",
       " ('root,l,r,r,l,l', 'Height', 173),\n",
       " ('root,l,r,r,l,r', 'Weight', 119),\n",
       " ('root,l,r,r,r,l', 'Weight', 93),\n",
       " ('root,r,l,r,l,r', 'Weight', 138),\n",
       " ('root,r,r,r,l,l', 'Weight', 146),\n",
       " ('root,l,l,l,l,l,l', 'Height', 149),\n",
       " ('root,l,l,l,l,r,r', 'Weight', 58),\n",
       " ('root,l,l,l,r,r,l', 'Weight', 73),\n",
       " ('root,l,l,l,r,r,r', 'Weight', 81),\n",
       " ('root,l,l,r,l,r,r', 'Gender', 0),\n",
       " ('root,l,l,r,r,r,l', 'Height', 177),\n",
       " ('root,l,l,r,r,r,r', 'Height', 189),\n",
       " ('root,l,r,l,l,l,r', 'Weight', 94),\n",
       " ('root,l,r,r,l,l,l', 'Weight', 87),\n",
       " ('root,l,r,r,l,r,l', 'Height', 168),\n",
       " ('root,l,r,r,l,r,r', 'Height', 174),\n",
       " ('root,l,r,r,r,l,l', 'Height', 191),\n",
       " ('root,l,r,r,r,l,r', 'Weight', 107),\n",
       " ('root,r,l,r,l,r,l', 'Weight', 137),\n",
       " ('root,r,r,r,l,l,l', 'Height', 187)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_conditions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>target</th>\n",
       "      <th>path</th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>root,l,l,l,r,r,l,l</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>root,l,r,r,l,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>root,l,l,l,l,r,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>root,l,l,r,l,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>root,l,r,r,r,l,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>root,l,l,l,l,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,l,l</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>158</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,l,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>root,l,r,l,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>root,l,r,r,r,l,l,l</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Height  Weight  target                path  value  prediction\n",
       "331       1     142      71       4  root,l,l,l,r,r,l,l      0           4\n",
       "374       1     174      95       4    root,l,r,r,l,l,r      0           3\n",
       "434       1     165      62       2  root,l,l,l,l,r,r,r      0           2\n",
       "354       1     190      50       0    root,l,l,r,l,l,r      0           0\n",
       "345       0     184     106       4  root,l,r,r,r,l,r,l      0           3\n",
       "..      ...     ...     ...     ...                 ...    ...         ...\n",
       "115       1     148      60       3    root,l,l,l,l,l,r      0           3\n",
       "102       1     161     155       5          root,r,l,l      0           5\n",
       "65        0     179     158       5        root,r,l,r,r      0           5\n",
       "87        1     145     117       5      root,l,r,l,r,l      0           5\n",
       "248       0     188      90       3  root,l,r,r,r,l,l,l      0           3\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = make_predictions(test, column_types, leaves, split_conditions)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(test, column_types, ml_task, leaves, split_conditions)\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['Height','Weight','Gender']]\n",
    "y_train = train[['target']]\n",
    "X_test = test[['Height','Weight','Gender']]\n",
    "y_test = test[['target']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with decision tree: 0.81\n",
      "Accuracy with decision tree in sklearn: 0.85\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train, sample_weight=None, check_input=True)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy with decision tree: {:.2f}\\nAccuracy with decision tree in sklearn: {:.2f}'.format(accuracy,accuracy_sklearn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
