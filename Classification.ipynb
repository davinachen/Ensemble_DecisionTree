{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from decisiontree import *"
=======
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
>>>>>>> Stashed changes
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 13,
=======
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(y, ml_task):\n",
    "    \n",
    "    if ml_task == \"regression\":\n",
    "        leaf = float(np.mean(y))\n",
    "    else:\n",
    "        counts = y.value_counts().reset_index()\n",
    "        leaf = counts.iloc[0,0]\n",
    "    \n",
    "    return leaf\n",
    "\n",
    "\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    X = data.drop(columns='target')\n",
    "    potential_splits = {}\n",
    "    columns = X.columns.tolist()\n",
    "    for column in columns:\n",
    "\n",
    "        values = X[[column]]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column] = unique_values - 1\n",
    "    \n",
    "    return potential_splits\n",
    "\n",
    "\n",
    "def calculate_gini(y):\n",
    "    \n",
    "    counts = y.value_counts().to_numpy()\n",
    "    probabilities = counts / counts.sum()\n",
    "    gini = np.sum(probabilities*(1-probabilities))\n",
    "     \n",
    "    return gini\n",
    "\n",
    "\n",
    "def calculate_mse(y):\n",
    "    \n",
    "    if len(y) == 0:\n",
    "        mse = 0\n",
    "    else:\n",
    "        mse = np.mean((y - np.mean(y)) **2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "\n",
    "def total_impurity(data_left, data_right, metric_function):\\\n",
    "\n",
    "    n = len(data_left) + len(data_right)\n",
    "    prop_left = len(data_left) / n\n",
    "    prop_right = len(data_right) / n\n",
    "\n",
    "    overall_metric =  (prop_left * metric_function(data_left['target']) \n",
    "                     + prop_right * metric_function(data_right['target']))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "def split_data(data, column_types, split_column, split_value):\n",
    "    \n",
    "    type_of_feature = column_types[split_column]\n",
    "\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_left = data[data[split_column] <= split_value]\n",
    "        data_right = data[data[split_column] >  split_value]\n",
    "    \n",
    "    else:\n",
    "        data_left = data[data[split_column] == split_value]\n",
    "        data_right = data[data[split_column] != split_value]\n",
    "    \n",
    "    return data_left, data_right\n",
    "\n",
    "\n",
    "def determine_best_split(data, column_types, potential_splits, ml_task):\n",
    "\n",
    "    best_overall_metric = np.inf\n",
    "    for column, splits in potential_splits.items():\n",
    "        for split in splits:\n",
    "            \n",
    "            data_left, data_right = split_data(data, column_types, split_column=column, split_value=split)\n",
    "            \n",
    "            if ml_task == \"regression\":\n",
    "                node_impurity = total_impurity(data_left, data_right, metric_function=calculate_mse)\n",
    "            else:\n",
    "                node_impurity = total_impurity(data_left, data_right, metric_function=calculate_gini)\n",
    "            \n",
    "            if node_impurity <= best_overall_metric:\n",
    "                best_overall_metric = node_impurity\n",
    "                best_split_column = column\n",
    "                best_split_value = split\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, column_types, ml_task, min_samples=2, max_depth=5):\n",
    "    \n",
    "    leaves = []\n",
    "    path = 'root'\n",
    "    datasets = [(df,path)]\n",
    "    split_conditions = []\n",
    "    for current_depth in range(max_depth+1):\n",
    "        next_set = []\n",
    "        for dataset in datasets:\n",
    "            data = dataset[0]\n",
    "            path = dataset[1]\n",
    "            \n",
    "            if (len(data.target.unique()) == 1) or (len(data) < min_samples):\n",
    "                leaf = create_leaf(data[['target']], ml_task)\n",
    "                leaves.append((path,leaf))\n",
    "                continue\n",
    "\n",
    "            potential_splits = get_potential_splits(data)\n",
    "            split_column, split_value = determine_best_split(data, column_types, potential_splits, ml_task)\n",
    "            data_left, data_right = split_data(data, column_types, split_column, split_value)\n",
    "\n",
    "            if len(data_left) == 0 or len(data_right) == 0:\n",
    "                leaf = create_leaf(data[['target']], ml_task)\n",
    "                leaves.append((path,leaf))\n",
    "                continue\n",
    "            print(len(data_left),len(data_right))\n",
    "            split_conditions.append((path,split_column,split_value))\n",
    "            next_set.append((data_left,path+',l'))\n",
    "            next_set.append((data_right,path+',r'))\n",
    "\n",
    "        datasets = next_set\n",
    "\n",
    "    for dataset in datasets:\n",
    "        data = dataset[0]\n",
    "        path = dataset[1]\n",
    "        leaf = create_leaf(data[['target']], ml_task)\n",
    "        leaves.append((path,leaf))\n",
    "\n",
    "    return leaves, split_conditions\n",
    "\n",
    "# Make predictions with decision tree\n",
    "\n",
    "def make_predictions(df, column_types, leaves, split_conditions):\n",
    "\n",
    "    df['path'] = 'root'\n",
    "    df['value'] = 0\n",
    "    \n",
    "    for split_condition in split_conditions:\n",
    "        path = split_condition[0]\n",
    "        column = split_condition[1]\n",
    "        value = split_condition[2]\n",
    "\n",
    "        if column_types[column] == \"continuous\":\n",
    "            df.loc[(df['path']==path)&(df[column]<= value),'path'] = path+',l'\n",
    "            df.loc[(df['path']==path)&(df[column]> value),'path'] = path+',r'\n",
    "        else:\n",
    "            df.loc[(df['path']==path)&(df[column]== value),'path'] = path+',l'\n",
    "            df.loc[(df['path']==path)&(df[column]!= value),'path'] = path+',r'\n",
    "\n",
    "    df['prediction'] = df['path'].map(dict(leaves))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_accuracy(df, column_types, ml_task, leaves, split_conditions):\n",
    "    predictions = make_predictions(df, column_types, leaves, split_conditions).prediction\n",
    "    \n",
    "    if ml_task == 'regression':    \n",
    "        metric = sum((predictions - df.target)**2) / len(predictions)\n",
    "    else:\n",
    "        predictions_correct = predictions == df.target\n",
    "        metric = predictions_correct.mean()\n",
    "    \n",
    "    return  metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read csvs\n",
    "train_df = pd.read_csv('data/classification/train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 14,
=======
   "execution_count": 63,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "## Filtering column \"mail_type\"\n",
    "train_x = train_df[['mail_type']]\n",
    "train_x = train_x.fillna(value='None')\n",
    "train_y = train_df[['label']]\n",
    "\n",
    "test_x = test_df[['mail_type']]\n",
    "test_x = test_x.fillna(value='None')\n",
    "\n",
    "## Do one hot encoding of categorical feature\n",
    "feat_enc = OneHotEncoder()\n",
    "feat_enc.fit(np.vstack([train_x, test_x]))\n",
    "train_x_featurized = feat_enc.transform(train_x)\n",
    "test_x_featurized = feat_enc.transform(test_x)"
=======
    "train_df = train_df.fillna(0)\n",
    "train_df = train_df[['images','urls','chars_in_subject','chars_in_body','label']].rename(columns={'label':'target'})\n",
    "train, val = train_test_split(train_df, test_size = 0.2)\n",
    "column_types = {'images':'continuous','urls':'continuous','chars_in_subject':'continuous','chars_in_body':'continuous'}\n",
    "ml_task = 'classifier'"
>>>>>>> Stashed changes
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Davina Chen\\Desktop\\DSBA\\T2\\Ensemble\\Project\\Ensemble_DecisionTree\\Classification.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Davina%20Chen/Desktop/DSBA/T2/Ensemble/Project/Ensemble_DecisionTree/Classification.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tree \u001b[39m=\u001b[39m decision_tree_algorithm(train_df, ml_task\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mclassification\u001b[39;49m\u001b[39m\"\u001b[39;49m, max_depth\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Davina Chen\\Desktop\\DSBA\\T2\\Ensemble\\Project\\Ensemble_DecisionTree\\decisiontree.py:164\u001b[0m, in \u001b[0;36mdecision_tree_algorithm\u001b[1;34m(df, ml_task, counter, min_samples, max_depth)\u001b[0m\n\u001b[0;32m    161\u001b[0m counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    163\u001b[0m \u001b[39m# helper functions \u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m potential_splits \u001b[39m=\u001b[39m get_potential_splits(data)\n\u001b[0;32m    165\u001b[0m split_column, split_value \u001b[39m=\u001b[39m determine_best_split(data, potential_splits, ml_task)\n\u001b[0;32m    166\u001b[0m data_below, data_above \u001b[39m=\u001b[39m split_data(data, split_column, split_value)\n",
      "File \u001b[1;32mc:\\Users\\Davina Chen\\Desktop\\DSBA\\T2\\Ensemble\\Project\\Ensemble_DecisionTree\\decisiontree.py:36\u001b[0m, in \u001b[0;36mget_potential_splits\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m column_index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_columns \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m): \u001b[39m# excluding the last column which is the label\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     values \u001b[39m=\u001b[39m data[:, column_index]\n\u001b[1;32m---> 36\u001b[0m     unique_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munique(values)\n\u001b[0;32m     38\u001b[0m     potential_splits[column_index] \u001b[39m=\u001b[39m unique_values\n\u001b[0;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m potential_splits\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    270\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    271\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts)\n\u001b[0;32m    273\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    275\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:333\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    331\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[0;32m    332\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[0;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[0;32m    335\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
=======
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29763 34377\n",
      "9766 19997\n",
      "18849 15528\n",
      "2021 7745\n",
      "4382 15615\n",
      "10083 8766\n",
      "2685 12843\n",
      "1167 854\n",
      "4863 2882\n",
      "1129 3253\n",
      "6162 9453\n",
      "9372 711\n",
      "2796 5970\n",
      "2523 162\n",
      "6539 6304\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "tree = decision_tree_algorithm(train_df, ml_task=\"classification\", max_depth=3)"
=======
    "leaves, split_conditions = decision_tree_algorithm(train, column_types, ml_task, min_samples=2, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root,l,l,l,l': 1,\n",
       " 'root,l,l,l,r': 1,\n",
       " 'root,l,l,r,l': 1,\n",
       " 'root,l,l,r,r': 1,\n",
       " 'root,l,r,l,l': 1,\n",
       " 'root,l,r,l,r': 1,\n",
       " 'root,l,r,r,l': 3,\n",
       " 'root,l,r,r,r': 1,\n",
       " 'root,r,l,l,l': 0,\n",
       " 'root,r,l,l,r': 0,\n",
       " 'root,r,l,r,l': 1,\n",
       " 'root,r,l,r,r': 1,\n",
       " 'root,r,r,l,l': 1,\n",
       " 'root,r,r,l,r': 1,\n",
       " 'root,r,r,r,l': 1,\n",
       " 'root,r,r,r,r': 1}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('root', 'images', 1),\n",
       " ('root,l', 'chars_in_subject', 29.0),\n",
       " ('root,r', 'chars_in_body', 31735),\n",
       " ('root,l,l', 'chars_in_subject', 11.0),\n",
       " ('root,l,r', 'chars_in_body', 1279),\n",
       " ('root,r,l', 'chars_in_subject', 40.0),\n",
       " ('root,r,r', 'urls', 40),\n",
       " ('root,l,l,l', 'chars_in_body', 6428),\n",
       " ('root,l,l,r', 'urls', 4),\n",
       " ('root,l,r,l', 'chars_in_body', 6),\n",
       " ('root,l,r,r', 'urls', 3),\n",
       " ('root,r,l,l', 'urls', 58),\n",
       " ('root,r,l,r', 'images', 3),\n",
       " ('root,r,r,l', 'chars_in_body', 1050392),\n",
       " ('root,r,r,r', 'chars_in_subject', 60.0)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_conditions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>urls</th>\n",
       "      <th>chars_in_subject</th>\n",
       "      <th>chars_in_body</th>\n",
       "      <th>target</th>\n",
       "      <th>path</th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>936846</td>\n",
       "      <td>1</td>\n",
       "      <td>root,l,l,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64746</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30433</td>\n",
       "      <td>0</td>\n",
       "      <td>root,r,l,l,l</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67311</th>\n",
       "      <td>27</td>\n",
       "      <td>205</td>\n",
       "      <td>177.0</td>\n",
       "      <td>92545</td>\n",
       "      <td>1</td>\n",
       "      <td>root,r,r,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24310</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>37.0</td>\n",
       "      <td>24689</td>\n",
       "      <td>1</td>\n",
       "      <td>root,r,l,l,l</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48041</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1186033</td>\n",
       "      <td>3</td>\n",
       "      <td>root,l,r,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32902</th>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>98.0</td>\n",
       "      <td>41336</td>\n",
       "      <td>1</td>\n",
       "      <td>root,r,r,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38494</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>root,l,r,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18225</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7155</td>\n",
       "      <td>3</td>\n",
       "      <td>root,l,l,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75334</th>\n",
       "      <td>90</td>\n",
       "      <td>260</td>\n",
       "      <td>37.0</td>\n",
       "      <td>84347</td>\n",
       "      <td>0</td>\n",
       "      <td>root,r,r,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54176</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10878</td>\n",
       "      <td>1</td>\n",
       "      <td>root,l,l,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16036 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       images  urls  chars_in_subject  chars_in_body  target          path  \\\n",
       "4027        0     0              11.0         936846       1  root,l,l,l,r   \n",
       "64746       4    21              31.0          30433       0  root,r,l,l,l   \n",
       "67311      27   205             177.0          92545       1  root,r,r,r,r   \n",
       "24310       4    14              37.0          24689       1  root,r,l,l,l   \n",
       "48041       0     0              52.0        1186033       3  root,l,r,r,l   \n",
       "...       ...   ...               ...            ...     ...           ...   \n",
       "32902       9    41              98.0          41336       1  root,r,r,r,r   \n",
       "38494       0     3              59.0            870       1  root,l,r,l,r   \n",
       "18225       0     0              24.0           7155       3  root,l,l,r,l   \n",
       "75334      90   260              37.0          84347       0  root,r,r,r,l   \n",
       "54176       0     6              29.0          10878       1  root,l,l,r,r   \n",
       "\n",
       "       value  prediction  \n",
       "4027       0           1  \n",
       "64746      0           0  \n",
       "67311      0           1  \n",
       "24310      0           0  \n",
       "48041      0           3  \n",
       "...      ...         ...  \n",
       "32902      0           1  \n",
       "38494      0           1  \n",
       "18225      0           1  \n",
       "75334      0           1  \n",
       "54176      0           1  \n",
       "\n",
       "[16036 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = make_predictions(val, column_types, leaves, split_conditions)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4727488151658768"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(val, column_types, ml_task, leaves, split_conditions)\n",
    "accuracy"
>>>>>>> Stashed changes
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
