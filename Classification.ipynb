{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(y, ml_task):\n",
    "    \n",
    "    if ml_task == \"regression\":\n",
    "        leaf = float(np.mean(y))\n",
    "    else:\n",
    "        counts = y.value_counts().reset_index()\n",
    "        leaf = counts.iloc[0,0]\n",
    "    \n",
    "    return leaf\n",
    "\n",
    "\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    X = data.drop(columns='target')\n",
    "    potential_splits = {}\n",
    "    columns = X.columns.tolist()\n",
    "    for column in columns:\n",
    "\n",
    "        values = X[[column]]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column] = unique_values - 1\n",
    "    \n",
    "    return potential_splits\n",
    "\n",
    "\n",
    "def calculate_gini(y):\n",
    "    \n",
    "    counts = y.value_counts().to_numpy()\n",
    "    probabilities = counts / counts.sum()\n",
    "    gini = np.sum(probabilities*(1-probabilities))\n",
    "     \n",
    "    return gini\n",
    "\n",
    "\n",
    "def calculate_mse(y):\n",
    "    \n",
    "    if len(y) == 0:\n",
    "        mse = 0\n",
    "    else:\n",
    "        mse = np.mean((y - np.mean(y)) **2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "\n",
    "def total_impurity(data_left, data_right, metric_function):\\\n",
    "\n",
    "    n = len(data_left) + len(data_right)\n",
    "    prop_left = len(data_left) / n\n",
    "    prop_right = len(data_right) / n\n",
    "\n",
    "    overall_metric =  (prop_left * metric_function(data_left['target']) \n",
    "                     + prop_right * metric_function(data_right['target']))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "def split_data(data, column_types, split_column, split_value):\n",
    "    \n",
    "    type_of_feature = column_types[split_column]\n",
    "\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_left = data[data[split_column] <= split_value]\n",
    "        data_right = data[data[split_column] >  split_value]\n",
    "    \n",
    "    else:\n",
    "        data_left = data[data[split_column] == split_value]\n",
    "        data_right = data[data[split_column] != split_value]\n",
    "    \n",
    "    return data_left, data_right\n",
    "\n",
    "\n",
    "def determine_best_split(data, column_types, potential_splits, ml_task):\n",
    "\n",
    "    best_overall_metric = np.inf\n",
    "    for column, splits in potential_splits.items():\n",
    "        for split in splits:\n",
    "            \n",
    "            data_left, data_right = split_data(data, column_types, split_column=column, split_value=split)\n",
    "            \n",
    "            if ml_task == \"regression\":\n",
    "                node_impurity = total_impurity(data_left, data_right, metric_function=calculate_mse)\n",
    "            else:\n",
    "                node_impurity = total_impurity(data_left, data_right, metric_function=calculate_gini)\n",
    "            \n",
    "            if node_impurity <= best_overall_metric:\n",
    "                best_overall_metric = node_impurity\n",
    "                best_split_column = column\n",
    "                best_split_value = split\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, column_types, ml_task, min_samples=2, max_depth=5):\n",
    "    \n",
    "    leaves = []\n",
    "    path = 'root'\n",
    "    datasets = [(df,path)]\n",
    "    split_conditions = []\n",
    "    for current_depth in range(max_depth+1):\n",
    "        next_set = []\n",
    "        for dataset in datasets:\n",
    "            data = dataset[0]\n",
    "            path = dataset[1]\n",
    "            \n",
    "            if (len(data.target.unique()) == 1) or (len(data) < min_samples):\n",
    "                leaf = create_leaf(data[['target']], ml_task)\n",
    "                leaves.append((path,leaf))\n",
    "                continue\n",
    "\n",
    "            potential_splits = get_potential_splits(data)\n",
    "            split_column, split_value = determine_best_split(data, column_types, potential_splits, ml_task)\n",
    "            data_left, data_right = split_data(data, column_types, split_column, split_value)\n",
    "\n",
    "            if len(data_left) == 0 or len(data_right) == 0:\n",
    "                leaf = create_leaf(data[['target']], ml_task)\n",
    "                leaves.append((path,leaf))\n",
    "                continue\n",
    "            print(len(data_left),len(data_right))\n",
    "            split_conditions.append((path,split_column,split_value))\n",
    "            next_set.append((data_left,path+',l'))\n",
    "            next_set.append((data_right,path+',r'))\n",
    "\n",
    "        datasets = next_set\n",
    "\n",
    "    for dataset in datasets:\n",
    "        data = dataset[0]\n",
    "        path = dataset[1]\n",
    "        leaf = create_leaf(data[['target']], ml_task)\n",
    "        leaves.append((path,leaf))\n",
    "\n",
    "    return leaves, split_conditions\n",
    "\n",
    "# Make predictions with decision tree\n",
    "\n",
    "def make_predictions(df, column_types, leaves, split_conditions):\n",
    "\n",
    "    df['path'] = 'root'\n",
    "    df['value'] = 0\n",
    "    \n",
    "    for split_condition in split_conditions:\n",
    "        path = split_condition[0]\n",
    "        column = split_condition[1]\n",
    "        value = split_condition[2]\n",
    "\n",
    "        if column_types[column] == \"continuous\":\n",
    "            df.loc[(df['path']==path)&(df[column]<= value),'path'] = path+',l'\n",
    "            df.loc[(df['path']==path)&(df[column]> value),'path'] = path+',r'\n",
    "        else:\n",
    "            df.loc[(df['path']==path)&(df[column]== value),'path'] = path+',l'\n",
    "            df.loc[(df['path']==path)&(df[column]!= value),'path'] = path+',r'\n",
    "\n",
    "    df['prediction'] = df['path'].map(dict(leaves))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_accuracy(df, column_types, ml_task, leaves, split_conditions):\n",
    "    predictions = make_predictions(df, column_types, leaves, split_conditions).prediction\n",
    "    \n",
    "    if ml_task == 'regression':    \n",
    "        predictions_array = predictions.values\n",
    "        target_array = df.target.values\n",
    "        metric = np.sqrt(sum((predictions_array - target_array)**2) / len(predictions_array))\n",
    "        \n",
    "    else:\n",
    "        predictions_correct = predictions == df.target\n",
    "        metric = predictions_correct.mean()\n",
    "    \n",
    "    return  metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read csvs\n",
    "train_df = pd.read_csv('500_Person_Gender_Height_Weight_Index.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "train_df = train_df.rename(columns={'Index':'target'})\n",
    "train, val = train_test_split(train_df, test_size = 0.2)\n",
    "column_types = {'Gender':'categorical','Height':'continuous','Weight':'continuous'}\n",
    "ml_task = 'classifier'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 279\n",
      "21 100\n",
      "109 170\n",
      "12 9\n",
      "8 92\n",
      "31 78\n",
      "114 56\n",
      "3 9\n",
      "6 3\n",
      "1 7\n",
      "51 41\n",
      "27 4\n",
      "46 68\n",
      "48 8\n",
      "1 2\n",
      "2 7\n",
      "2 1\n",
      "24 27\n",
      "20 21\n",
      "16 11\n",
      "17 29\n",
      "8 60\n",
      "7 41\n",
      "7 1\n",
      "22 2\n",
      "8 19\n",
      "9 11\n",
      "19 2\n",
      "12 4\n",
      "12 5\n",
      "26 3\n",
      "5 3\n",
      "47 13\n",
      "4 3\n",
      "35 6\n",
      "4 3\n"
     ]
    }
   ],
   "source": [
    "leaves, split_conditions = decision_tree_algorithm(train, column_types, ml_task, min_samples=2, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root,r,l,r': 5,\n",
       " 'root,l,l,r,l': 4,\n",
       " 'root,l,r,l,l': 1,\n",
       " 'root,l,r,l,r': 0,\n",
       " 'root,r,l,l,r': 4,\n",
       " 'root,l,l,l,l,l': 3,\n",
       " 'root,l,l,l,l,r': 2,\n",
       " 'root,l,l,l,r,l': 4,\n",
       " 'root,l,l,l,r,r': 3,\n",
       " 'root,l,l,r,r,l': 5,\n",
       " 'root,l,l,r,r,r': 4,\n",
       " 'root,r,l,l,l,r': 5,\n",
       " 'root,r,r,r,r,r': 5,\n",
       " 'root,l,r,r,l,l,l': 2,\n",
       " 'root,l,r,r,l,l,r': 2,\n",
       " 'root,l,r,r,l,r,l': 0,\n",
       " 'root,l,r,r,l,r,r': 1,\n",
       " 'root,l,r,r,r,l,l': 3,\n",
       " 'root,l,r,r,r,l,r': 2,\n",
       " 'root,l,r,r,r,r,l': 2,\n",
       " 'root,l,r,r,r,r,r': 3,\n",
       " 'root,r,l,l,l,l,l': 5,\n",
       " 'root,r,l,l,l,l,r': 4,\n",
       " 'root,r,r,l,l,l,l': 4,\n",
       " 'root,r,r,l,l,l,r': 4,\n",
       " 'root,r,r,l,l,r,l': 3,\n",
       " 'root,r,r,l,l,r,r': 2,\n",
       " 'root,r,r,l,r,l,l': 4,\n",
       " 'root,r,r,l,r,l,r': 5,\n",
       " 'root,r,r,l,r,r,l': 4,\n",
       " 'root,r,r,l,r,r,r': 4,\n",
       " 'root,r,r,r,l,l,l': 5,\n",
       " 'root,r,r,r,l,l,r': 4,\n",
       " 'root,r,r,r,l,r,l': 5,\n",
       " 'root,r,r,r,l,r,r': 5,\n",
       " 'root,r,r,r,r,l,l': 4,\n",
       " 'root,r,r,r,r,l,r': 4}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('root', 'Weight', 84),\n",
       " ('root,l', 'Height', 152),\n",
       " ('root,r', 'Height', 166),\n",
       " ('root,l,l', 'Weight', 68),\n",
       " ('root,l,r', 'Weight', 50),\n",
       " ('root,r,l', 'Weight', 106),\n",
       " ('root,r,r', 'Weight', 137),\n",
       " ('root,l,l,l', 'Weight', 59),\n",
       " ('root,l,l,r', 'Weight', 78),\n",
       " ('root,l,r,l', 'Height', 181),\n",
       " ('root,l,r,r', 'Weight', 69),\n",
       " ('root,r,l,l', 'Height', 160),\n",
       " ('root,r,r,l', 'Weight', 105),\n",
       " ('root,r,r,r', 'Height', 191),\n",
       " ('root,l,l,l,l', 'Height', 147),\n",
       " ('root,l,l,l,r', 'Height', 147),\n",
       " ('root,l,l,r,r', 'Weight', 83),\n",
       " ('root,l,r,r,l', 'Height', 173),\n",
       " ('root,l,r,r,r', 'Height', 179),\n",
       " ('root,r,l,l,l', 'Weight', 95),\n",
       " ('root,r,r,l,l', 'Height', 177),\n",
       " ('root,r,r,l,r', 'Height', 171),\n",
       " ('root,r,r,r,l', 'Weight', 139),\n",
       " ('root,r,r,r,r', 'Weight', 158),\n",
       " ('root,l,r,r,l,l', 'Weight', 67),\n",
       " ('root,l,r,r,l,r', 'Weight', 55),\n",
       " ('root,l,r,r,r,l', 'Weight', 77),\n",
       " ('root,l,r,r,r,r', 'Weight', 83),\n",
       " ('root,r,l,l,l,l', 'Height', 151),\n",
       " ('root,r,r,l,l,l', 'Height', 173),\n",
       " ('root,r,r,l,l,r', 'Height', 196),\n",
       " ('root,r,r,l,r,l', 'Weight', 119),\n",
       " ('root,r,r,l,r,r', 'Height', 191),\n",
       " ('root,r,r,r,l,l', 'Height', 180),\n",
       " ('root,r,r,r,l,r', 'Height', 185),\n",
       " ('root,r,r,r,r,l', 'Weight', 152)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_conditions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>target</th>\n",
       "      <th>path</th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>153</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>root,l,r,r,l,l,l</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>153</td>\n",
       "      <td>149</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>141</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>root,l,l,r,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>156</td>\n",
       "      <td>106</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,l,l,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>185</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>root,l,r,r,l,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>144</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>root,l,l,r,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>189</td>\n",
       "      <td>124</td>\n",
       "      <td>4</td>\n",
       "      <td>root,r,r,l,r,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>195</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>root,r,r,l,l,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>163</td>\n",
       "      <td>137</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>161</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>root,l,r,r,r,l,l</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Height  Weight  target              path  value  prediction\n",
       "Gender                                                             \n",
       "Female     153      51       2  root,l,r,r,l,l,l      0           2\n",
       "Female     153     149       5        root,r,l,r      0           5\n",
       "Male       141      80       5    root,l,l,r,r,l      0           5\n",
       "Female     156     106       5    root,r,l,l,l,r      0           5\n",
       "Male       185      60       1  root,l,r,r,l,r,r      0           1\n",
       "...        ...     ...     ...               ...    ...         ...\n",
       "Male       144      80       4    root,l,l,r,r,l      0           5\n",
       "Female     189     124       4  root,r,r,l,r,r,l      0           4\n",
       "Male       195      98       3  root,r,r,l,l,r,l      0           3\n",
       "Male       163     137       5        root,r,l,r      0           5\n",
       "Male       161      72       3  root,l,r,r,r,l,l      0           3\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = make_predictions(val, column_types, leaves, split_conditions)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(val, column_types, ml_task, leaves, split_conditions)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
