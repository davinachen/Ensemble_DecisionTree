{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(y, ml_task):\n",
    "    \n",
    "    if ml_task == \"regression\":\n",
    "        leaf = float(np.mean(y))\n",
    "    else:\n",
    "        counts = y.value_counts().reset_index()\n",
    "        leaf = counts.iloc[0,0]\n",
    "    \n",
    "    return leaf\n",
    "\n",
    "\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    X = data.drop(columns='target')\n",
    "    potential_splits = {}\n",
    "    columns = X.columns.tolist()\n",
    "    for column in columns:\n",
    "\n",
    "        values = X[[column]]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column] = unique_values - 1\n",
    "    \n",
    "    return potential_splits\n",
    "\n",
    "\n",
    "def calculate_gini(y):\n",
    "    \n",
    "    counts = y.value_counts().to_numpy()\n",
    "    probabilities = counts / counts.sum()\n",
    "    gini = np.sum(probabilities*(1-probabilities))\n",
    "     \n",
    "    return gini\n",
    "\n",
    "\n",
    "def calculate_mse(y):\n",
    "    \n",
    "    if len(y) == 0:\n",
    "        mse = 0\n",
    "    else:\n",
    "        mse = np.mean((y - np.mean(y)) **2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "\n",
    "def total_impurity(data_left, data_right, metric_function):\\\n",
    "\n",
    "    n = len(data_left) + len(data_right)\n",
    "    prop_left = len(data_left) / n\n",
    "    prop_right = len(data_right) / n\n",
    "\n",
    "    overall_metric =  (prop_left * metric_function(data_left['target']) \n",
    "                     + prop_right * metric_function(data_right['target']))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "def split_data(data, column_types, split_column, split_value):\n",
    "    \n",
    "    type_of_feature = column_types[split_column]\n",
    "\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_left = data[data[split_column] <= split_value]\n",
    "        data_right = data[data[split_column] >  split_value]\n",
    "    \n",
    "    else:\n",
    "        data_left = data[data[split_column] == split_value]\n",
    "        data_right = data[data[split_column] != split_value]\n",
    "    \n",
    "    return data_left, data_right\n",
    "\n",
    "\n",
    "def determine_best_split(data, column_types, potential_splits, ml_task):\n",
    "\n",
    "    best_overall_metric = np.inf\n",
    "    for column, splits in potential_splits.items():\n",
    "        for split in splits:\n",
    "            \n",
    "            data_left, data_right = split_data(data, column_types, split_column=column, split_value=split)\n",
    "            \n",
    "            if ml_task == \"regression\":\n",
    "                node_impurity = total_impurity(data_left, data_right, metric_function=calculate_mse)\n",
    "            else:\n",
    "                node_impurity = total_impurity(data_left, data_right, metric_function=calculate_gini)\n",
    "            \n",
    "            if node_impurity <= best_overall_metric:\n",
    "                best_overall_metric = node_impurity\n",
    "                best_split_column = column\n",
    "                best_split_value = split\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, column_types, ml_task, min_samples=2, max_depth=5):\n",
    "    \n",
    "    leaves = []\n",
    "    path = 'root'\n",
    "    datasets = [(df,path)]\n",
    "    split_conditions = []\n",
    "    for current_depth in range(max_depth+1):\n",
    "        next_set = []\n",
    "        for dataset in datasets:\n",
    "            data = dataset[0]\n",
    "            path = dataset[1]\n",
    "            \n",
    "            if (len(data.target.unique()) == 1) or (len(data) < min_samples):\n",
    "                leaf = create_leaf(data[['target']], ml_task)\n",
    "                leaves.append((path,leaf))\n",
    "                continue\n",
    "\n",
    "            potential_splits = get_potential_splits(data)\n",
    "            split_column, split_value = determine_best_split(data, column_types, potential_splits, ml_task)\n",
    "            data_left, data_right = split_data(data, column_types, split_column, split_value)\n",
    "\n",
    "            if len(data_left) == 0 or len(data_right) == 0:\n",
    "                leaf = create_leaf(data[['target']], ml_task)\n",
    "                leaves.append((path,leaf))\n",
    "                continue\n",
    "            print(len(data_left),len(data_right))\n",
    "            split_conditions.append((path,split_column,split_value))\n",
    "            next_set.append((data_left,path+',l'))\n",
    "            next_set.append((data_right,path+',r'))\n",
    "\n",
    "        datasets = next_set\n",
    "\n",
    "    for dataset in datasets:\n",
    "        data = dataset[0]\n",
    "        path = dataset[1]\n",
    "        leaf = create_leaf(data[['target']], ml_task)\n",
    "        leaves.append((path,leaf))\n",
    "\n",
    "    return leaves, split_conditions\n",
    "\n",
    "# Make predictions with decision tree\n",
    "\n",
    "def make_predictions(df, column_types, leaves, split_conditions):\n",
    "\n",
    "    df['path'] = 'root'\n",
    "    df['value'] = 0\n",
    "    \n",
    "    for split_condition in split_conditions:\n",
    "        path = split_condition[0]\n",
    "        column = split_condition[1]\n",
    "        value = split_condition[2]\n",
    "\n",
    "        if column_types[column] == \"continuous\":\n",
    "            df.loc[(df['path']==path)&(df[column]<= value),'path'] = path+',l'\n",
    "            df.loc[(df['path']==path)&(df[column]> value),'path'] = path+',r'\n",
    "        else:\n",
    "            df.loc[(df['path']==path)&(df[column]== value),'path'] = path+',l'\n",
    "            df.loc[(df['path']==path)&(df[column]!= value),'path'] = path+',r'\n",
    "\n",
    "    df['prediction'] = df['path'].map(dict(leaves))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_accuracy(df, column_types, ml_task, leaves, split_conditions):\n",
    "    predictions = make_predictions(df, column_types, leaves, split_conditions).prediction\n",
    "    \n",
    "    if ml_task == 'regression':    \n",
    "        predictions_array = predictions.values\n",
    "        target_array = df.target.values\n",
    "        metric = np.sqrt(sum((predictions_array - target_array)**2) / len(predictions_array))\n",
    "        \n",
    "    else:\n",
    "        predictions_correct = predictions == df.target\n",
    "        metric = predictions_correct.mean()\n",
    "    \n",
    "    return  metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read csvs\n",
    "train_df = pd.read_csv('500_Person_Gender_Height_Weight_Index.csv')\n",
    "\n",
    "# Filling  NA\n",
    "train_df = train_df.fillna(0)\n",
    "train_df = train_df.rename(columns={'Height':'target'})\n",
    "\n",
    "# categorical variable encoding\n",
    "labelencoder = LabelEncoder()\n",
    "train_df['Gender'] = labelencoder.fit_transform(train_df['Gender'])\n",
    "\n",
    "# train-test split\n",
    "train, test = train_test_split(train_df, test_size = 0.2, random_state=50)\n",
    "column_types = {'Gender':'categorical','Weight':'continuous','Index':'categorical'}\n",
    "ml_task = 'regression'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 381\n",
      "11 8\n",
      "96 285\n",
      "4 7\n",
      "3 5\n",
      "36 60\n",
      "48 237\n",
      "1 3\n",
      "2 5\n",
      "2 1\n",
      "4 1\n",
      "11 25\n",
      "17 43\n",
      "20 28\n",
      "10 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "2 3\n",
      "3 1\n",
      "6 5\n",
      "13 12\n",
      "14 3\n",
      "25 18\n",
      "9 11\n",
      "26 2\n",
      "4 6\n",
      "24 203\n",
      "1 1\n",
      "2 1\n",
      "4 2\n",
      "3 2\n",
      "8 5\n",
      "7 5\n",
      "6 8\n",
      "2 1\n",
      "14 11\n",
      "13 5\n",
      "1 8\n",
      "3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8\n",
      "15 11\n",
      "1 1\n",
      "3 1\n",
      "3 3\n",
      "8 16\n",
      "57 146\n",
      "1 3\n",
      "1 1\n",
      "2 1\n",
      "1 1\n",
      "5 3\n",
      "2 3\n",
      "2 5\n",
      "2 3\n",
      "2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4\n",
      "5 3\n",
      "9 5\n",
      "10 1\n",
      "6 7\n",
      "3 2\n",
      "4 4\n",
      "2 1\n",
      "6 2\n",
      "7 8\n",
      "6 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "1 2\n",
      "1 7\n",
      "11 5\n",
      "25 32\n",
      "58 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "leaves, split_conditions = decision_tree_algorithm(train, column_types, ml_task, min_samples=2, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root,l,l,l,l': 168.0,\n",
       " 'root,l,l,r,l': 179.0,\n",
       " 'root,l,r,l,l': 194.0,\n",
       " 'root,l,r,l,r': 195.0,\n",
       " 'root,l,r,r,r': 196.0,\n",
       " 'root,l,l,l,r,l': 178.0,\n",
       " 'root,l,l,r,r,l': 180.0,\n",
       " 'root,l,r,r,l,l': 189.66666666666666,\n",
       " 'root,l,r,r,l,r': 188.0,\n",
       " 'root,l,l,l,r,r,l': 170.0,\n",
       " 'root,l,l,l,r,r,r': 176.0,\n",
       " 'root,l,l,r,r,r,l': 186.0,\n",
       " 'root,l,l,r,r,r,r': 185.0,\n",
       " 'root,r,l,r,l,r,l': 176.5,\n",
       " 'root,r,l,r,l,r,r': 181.0,\n",
       " 'root,r,r,l,l,l,l': 150.0,\n",
       " 'root,r,r,l,r,r,l': 192.0,\n",
       " 'root,r,r,l,r,r,r': 199.0,\n",
       " 'root,r,r,r,l,l,l': 190.33333333333334,\n",
       " 'root,r,r,r,l,l,r': 198.0,\n",
       " 'root,r,l,l,l,l,l,l': 144.0,\n",
       " 'root,r,l,l,l,l,l,r': 148.33333333333334,\n",
       " 'root,r,l,l,l,l,r,l': 142.0,\n",
       " 'root,r,l,l,l,l,r,r': 146.0,\n",
       " 'root,r,l,l,l,r,l,l': 153.5,\n",
       " 'root,r,l,l,l,r,l,r': 153.0,\n",
       " 'root,r,l,l,l,r,r,l': 144.0,\n",
       " 'root,r,l,l,l,r,r,r': 154.0,\n",
       " 'root,r,l,l,r,l,l,l': 164.6,\n",
       " 'root,r,l,l,r,l,l,r': 153.33333333333334,\n",
       " 'root,r,l,l,r,l,r,l': 148.5,\n",
       " 'root,r,l,l,r,l,r,r': 163.66666666666666,\n",
       " 'root,r,l,l,r,r,l,l': 174.5,\n",
       " 'root,r,l,l,r,r,l,r': 172.8,\n",
       " 'root,r,l,l,r,r,r,l': 166.0,\n",
       " 'root,r,l,l,r,r,r,r': 162.66666666666666,\n",
       " 'root,r,l,r,l,l,l,l': 179.5,\n",
       " 'root,r,l,r,l,l,l,r': 174.0,\n",
       " 'root,r,l,r,l,l,r,l': 171.6,\n",
       " 'root,r,l,r,l,l,r,r': 176.66666666666666,\n",
       " 'root,r,l,r,r,l,l,l': 179.11111111111111,\n",
       " 'root,r,l,r,r,l,l,r': 185.8,\n",
       " 'root,r,l,r,r,l,r,l': 187.1,\n",
       " 'root,r,l,r,r,l,r,r': 179.0,\n",
       " 'root,r,l,r,r,r,l,l': 191.66666666666666,\n",
       " 'root,r,l,r,r,r,l,r': 188.14285714285714,\n",
       " 'root,r,l,r,r,r,r,l': 193.0,\n",
       " 'root,r,l,r,r,r,r,r': 197.0,\n",
       " 'root,r,r,l,l,l,r,l': 156.0,\n",
       " 'root,r,r,l,l,l,r,r': 154.25,\n",
       " 'root,r,r,l,l,r,l,l': 164.5,\n",
       " 'root,r,r,l,l,r,l,r': 164.0,\n",
       " 'root,r,r,l,l,r,r,l': 171.5,\n",
       " 'root,r,r,l,l,r,r,r': 164.5,\n",
       " 'root,r,r,l,r,l,l,l': 184.85714285714286,\n",
       " 'root,r,r,l,r,l,l,r': 175.25,\n",
       " 'root,r,r,l,r,l,r,l': 180.66666666666666,\n",
       " 'root,r,r,l,r,l,r,r': 192.6,\n",
       " 'root,r,r,r,l,r,l,l': 185.0,\n",
       " 'root,r,r,r,l,r,l,r': 160.5,\n",
       " 'root,r,r,r,l,r,r,l': 191.0,\n",
       " 'root,r,r,r,l,r,r,r': 190.5,\n",
       " 'root,r,r,r,r,l,l,l': 163.0,\n",
       " 'root,r,r,r,r,l,l,r': 150.85714285714286,\n",
       " 'root,r,r,r,r,l,r,l': 162.45454545454547,\n",
       " 'root,r,r,r,r,l,r,r': 150.8,\n",
       " 'root,r,r,r,r,r,l,l': 173.92,\n",
       " 'root,r,r,r,r,r,l,r': 165.40625,\n",
       " 'root,r,r,r,r,r,r,l': 160.20689655172413,\n",
       " 'root,r,r,r,r,r,r,r': 166.3068181818182}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(leaves)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>target</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Index</th>\n",
       "      <th>path</th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>root,r,l,l,l,l,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>root,r,l,l,r,l,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>163.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>root,r,r,l,l,r,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>171.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>root,r,r,r,l,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>198.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>root,r,l,r,l,l,l,l</td>\n",
       "      <td>0</td>\n",
       "      <td>179.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>root,r,r,r,r,l,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>150.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,r,r,r,r,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>166.306818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>158</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,r,r,r,r,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>166.306818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,r,r,r,r,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>160.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>root,r,r,r,r,r,l,l</td>\n",
       "      <td>0</td>\n",
       "      <td>173.920000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  target  Weight  Index                path  value  prediction\n",
       "331       1     142      71      4  root,r,l,l,l,l,r,r      0  146.000000\n",
       "374       1     174      95      4  root,r,l,l,r,l,r,r      0  163.666667\n",
       "434       1     165      62      2  root,r,r,l,l,r,r,l      0  171.500000\n",
       "354       1     190      50      0    root,r,r,r,l,l,r      0  198.000000\n",
       "345       0     184     106      4  root,r,l,r,l,l,l,l      0  179.500000\n",
       "..      ...     ...     ...    ...                 ...    ...         ...\n",
       "115       1     148      60      3  root,r,r,r,r,l,l,r      0  150.857143\n",
       "102       1     161     155      5  root,r,r,r,r,r,r,r      0  166.306818\n",
       "65        0     179     158      5  root,r,r,r,r,r,r,r      0  166.306818\n",
       "87        1     145     117      5  root,r,r,r,r,r,r,l      0  160.206897\n",
       "248       0     188      90      3  root,r,r,r,r,r,l,l      0  173.920000\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = make_predictions(test, column_types, leaves, split_conditions)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.787737305387969"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = calculate_accuracy(test, column_types, ml_task, leaves, split_conditions)\n",
    "RMSE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['Index','Weight','Gender']]\n",
    "y_train = train[['target']]\n",
    "X_test = test[['Index','Weight','Gender']]\n",
    "y_test = test[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with decision tree: 10.79\n",
      "RMSE with decision tree in sklearn: 13.82\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train, sample_weight=None, check_input=True)\n",
    "y_pred = clf.predict(X_test)\n",
    "rmse_sklearn = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE with decision tree: {:.2f}\\nRMSE with decision tree in sklearn: {:.2f}'.format(RMSE,rmse_sklearn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
