{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(y, ml_task):\n",
    "    \n",
    "    if ml_task == \"regression\":\n",
    "        leaf = float(np.mean(y))\n",
    "    else:\n",
    "        counts = y.value_counts().reset_index()\n",
    "        leaf = counts.iloc[0,0]\n",
    "    \n",
    "    return leaf\n",
    "\n",
    "\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    X = data.drop(columns='target')\n",
    "    potential_splits = {}\n",
    "    columns = X.columns.tolist()\n",
    "    for column in columns:\n",
    "\n",
    "        values = X[[column]]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column] = unique_values - 1\n",
    "    \n",
    "    return potential_splits\n",
    "\n",
    "\n",
    "def calculate_gini(y):\n",
    "    \n",
    "    counts = y.value_counts().to_numpy()\n",
    "    probabilities = counts / counts.sum()\n",
    "    gini = np.sum(probabilities*(1-probabilities))\n",
    "     \n",
    "    return gini\n",
    "\n",
    "\n",
    "def calculate_mse(y):\n",
    "    \n",
    "    if len(y) == 0:\n",
    "        mse = 0\n",
    "    else:\n",
    "        mse = np.mean((y - np.mean(y)) **2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "\n",
    "def total_impurity(data_left, data_right, metric_function):\\\n",
    "\n",
    "    n = len(data_left) + len(data_right)\n",
    "    prop_left = len(data_left) / n\n",
    "    prop_right = len(data_right) / n\n",
    "\n",
    "    overall_metric =  (prop_left * metric_function(data_left['target']) \n",
    "                     + prop_right * metric_function(data_right['target']))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "def split_data(data, column_types, split_column, split_value):\n",
    "    \n",
    "    type_of_feature = column_types[split_column]\n",
    "\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_left = data[data[split_column] <= split_value]\n",
    "        data_right = data[data[split_column] >  split_value]\n",
    "    \n",
    "    else:\n",
    "        data_left = data[data[split_column] == split_value]\n",
    "        data_right = data[data[split_column] != split_value]\n",
    "    \n",
    "    return data_left, data_right\n",
    "\n",
    "\n",
    "def determine_best_split(data, column_types, potential_splits, ml_task):\n",
    "\n",
    "    best_overall_metric = np.inf\n",
    "    for column, splits in potential_splits.items():\n",
    "        for split in splits:\n",
    "            \n",
    "            data_left, data_right = split_data(data, column_types, split_column=column, split_value=split)\n",
    "            \n",
    "            if ml_task == \"regression\":\n",
    "                node_impurity = total_impurity(data_left, data_right, metric_function=calculate_mse)\n",
    "            else:\n",
    "                node_impurity = total_impurity(data_left, data_right, metric_function=calculate_gini)\n",
    "            \n",
    "            if node_impurity <= best_overall_metric:\n",
    "                best_overall_metric = node_impurity\n",
    "                best_split_column = column\n",
    "                best_split_value = split\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, column_types, ml_task, min_samples=2, max_depth=5):\n",
    "    \n",
    "    leaves = []\n",
    "    path = 'root'\n",
    "    datasets = [(df,path)]\n",
    "    split_conditions = []\n",
    "    for current_depth in range(max_depth+1):\n",
    "        next_set = []\n",
    "        for dataset in datasets:\n",
    "            data = dataset[0]\n",
    "            path = dataset[1]\n",
    "            \n",
    "            if (len(data.target.unique()) == 1) or (len(data) < min_samples):\n",
    "                leaf = create_leaf(data[['target']], ml_task)\n",
    "                leaves.append((path,leaf))\n",
    "                continue\n",
    "\n",
    "            potential_splits = get_potential_splits(data)\n",
    "            split_column, split_value = determine_best_split(data, column_types, potential_splits, ml_task)\n",
    "            data_left, data_right = split_data(data, column_types, split_column, split_value)\n",
    "\n",
    "            if len(data_left) == 0 or len(data_right) == 0:\n",
    "                leaf = create_leaf(data[['target']], ml_task)\n",
    "                leaves.append((path,leaf))\n",
    "                continue\n",
    "            print(len(data_left),len(data_right))\n",
    "            split_conditions.append((path,split_column,split_value))\n",
    "            next_set.append((data_left,path+',l'))\n",
    "            next_set.append((data_right,path+',r'))\n",
    "\n",
    "        datasets = next_set\n",
    "\n",
    "    for dataset in datasets:\n",
    "        data = dataset[0]\n",
    "        path = dataset[1]\n",
    "        leaf = create_leaf(data[['target']], ml_task)\n",
    "        leaves.append((path,leaf))\n",
    "\n",
    "    return leaves, split_conditions\n",
    "\n",
    "# Make predictions with decision tree\n",
    "\n",
    "def make_predictions(df, column_types, leaves, split_conditions):\n",
    "\n",
    "    df['path'] = 'root'\n",
    "    df['value'] = 0\n",
    "    \n",
    "    for split_condition in split_conditions:\n",
    "        path = split_condition[0]\n",
    "        column = split_condition[1]\n",
    "        value = split_condition[2]\n",
    "\n",
    "        if column_types[column] == \"continuous\":\n",
    "            df.loc[(df['path']==path)&(df[column]<= value),'path'] = path+',l'\n",
    "            df.loc[(df['path']==path)&(df[column]> value),'path'] = path+',r'\n",
    "        else:\n",
    "            df.loc[(df['path']==path)&(df[column]== value),'path'] = path+',l'\n",
    "            df.loc[(df['path']==path)&(df[column]!= value),'path'] = path+',r'\n",
    "\n",
    "    df['prediction'] = df['path'].map(dict(leaves))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_accuracy(df, column_types, ml_task, leaves, split_conditions):\n",
    "    predictions = make_predictions(df, column_types, leaves, split_conditions).prediction\n",
    "    \n",
    "    if ml_task == 'regression':    \n",
    "        predictions_array = predictions.values\n",
    "        target_array = df.target.values\n",
    "        metric = np.sqrt(sum((predictions_array - target_array)**2) / len(predictions_array))\n",
    "        \n",
    "    else:\n",
    "        predictions_correct = predictions == df.target\n",
    "        metric = predictions_correct.mean()\n",
    "    \n",
    "    return  metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read csvs\n",
    "train_df = pd.read_csv('500_Person_Gender_Height_Weight_Index.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.fillna(0)\n",
    "train_df = train_df.rename(columns={'Height':'target'})\n",
    "train, val = train_test_split(train_df, test_size = 0.2)\n",
    "column_types = {'Gender':'categorical','Weight':'continuous','Index':'categorical'}\n",
    "ml_task = 'regression'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 383\n",
      "9 8\n",
      "7 376\n",
      "1 8\n",
      "6 2\n",
      "56 320\n",
      "3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5\n",
      "2 4\n",
      "22 34\n",
      "96 224\n",
      "2 1\n",
      "2 3\n",
      "2 2\n",
      "8 14\n",
      "13 21\n",
      "35"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61\n",
      "58 166\n",
      "1 1\n",
      "2 1\n",
      "3 5\n",
      "9 5\n",
      "9 4\n",
      "20 1\n",
      "14 21\n",
      "23"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38\n",
      "26 32\n",
      "77 89\n",
      "1 2\n",
      "2 3\n",
      "8 1\n",
      "4 1\n",
      "2 7\n",
      "1 3\n",
      "15 5\n",
      "11 3\n",
      "12 9\n",
      "8"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15\n",
      "35 3\n",
      "12 14\n",
      "16 16\n",
      "3 74\n",
      "14 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "c:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "leaves, split_conditions = decision_tree_algorithm(train, column_types, ml_task, min_samples=2, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root,r,l': 191.0,\n",
       " 'root,l,l,l': 168.0,\n",
       " 'root,l,r,r': 195.5,\n",
       " 'root,l,r,l,l': 194.0,\n",
       " 'root,l,l,r,l,r': 179.0,\n",
       " 'root,l,l,r,r,l': 186.0,\n",
       " 'root,l,r,l,r,l': 191.0,\n",
       " 'root,l,r,l,r,r': 190.5,\n",
       " 'root,l,l,r,l,l,l': 178.0,\n",
       " 'root,l,l,r,l,l,r': 176.0,\n",
       " 'root,l,l,r,r,r,l': 180.0,\n",
       " 'root,l,l,r,r,r,r': 185.0,\n",
       " 'root,r,r,l,r,r,r': 168.0,\n",
       " 'root,r,r,l,l,l,l,l': 150.0,\n",
       " 'root,r,r,l,l,l,l,r': 149.0,\n",
       " 'root,r,r,l,l,l,r,l': 151.0,\n",
       " 'root,r,r,l,l,l,r,r': 152.33333333333334,\n",
       " 'root,r,r,l,l,r,l,l': 161.125,\n",
       " 'root,r,r,l,l,r,l,r': 162.0,\n",
       " 'root,r,r,l,l,r,r,l': 167.0,\n",
       " 'root,r,r,l,l,r,r,r': 170.0,\n",
       " 'root,r,r,l,r,l,l,l': 178.5,\n",
       " 'root,r,r,l,r,l,l,r': 180.42857142857142,\n",
       " 'root,r,r,l,r,l,r,l': 187.0,\n",
       " 'root,r,r,l,r,l,r,r': 182.33333333333334,\n",
       " 'root,r,r,l,r,r,l,l': 189.0,\n",
       " 'root,r,r,l,r,r,l,r': 195.0,\n",
       " 'root,r,r,r,l,l,l,l': 147.0,\n",
       " 'root,r,r,r,l,l,l,r': 152.33333333333334,\n",
       " 'root,r,r,r,l,l,r,l': 158.16666666666666,\n",
       " 'root,r,r,r,l,l,r,r': 164.66666666666666,\n",
       " 'root,r,r,r,l,r,l,l': 171.75,\n",
       " 'root,r,r,r,l,r,l,r': 176.13333333333333,\n",
       " 'root,r,r,r,l,r,r,l': 185.68571428571428,\n",
       " 'root,r,r,r,l,r,r,r': 197.66666666666666,\n",
       " 'root,r,r,r,r,l,l,l': 169.75,\n",
       " 'root,r,r,r,r,l,l,r': 165.5,\n",
       " 'root,r,r,r,r,l,r,l': 181.375,\n",
       " 'root,r,r,r,r,l,r,r': 173.0625,\n",
       " 'root,r,r,r,r,r,l,l': 141.33333333333334,\n",
       " 'root,r,r,r,r,r,l,r': 156.95945945945945,\n",
       " 'root,r,r,r,r,r,r,l': 172.57142857142858,\n",
       " 'root,r,r,r,r,r,r,r': 164.85333333333332}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(leaves)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Index</th>\n",
       "      <th>path</th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>164</td>\n",
       "      <td>160</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,r,r,r,r,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>164.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>193</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>root,r,r,r,l,r,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>185.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>151</td>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,r,r,r,r,r,r</td>\n",
       "      <td>0</td>\n",
       "      <td>164.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>141</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,r,r,r,r,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>156.959459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>154</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,r,r,r,r,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>156.959459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>155</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>root,r,r,r,r,l,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>165.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>187</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>root,l,r,l,r,l</td>\n",
       "      <td>0</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>183</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>root,r,r,l,r,r,l,l</td>\n",
       "      <td>0</td>\n",
       "      <td>189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>144</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,r,r,r,r,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>156.959459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>149</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>root,r,r,r,r,r,l,r</td>\n",
       "      <td>0</td>\n",
       "      <td>156.959459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target  Weight  Index                path  value  prediction\n",
       "Gender                                                              \n",
       "Female     164     160      5  root,r,r,r,r,r,r,r      0  164.853333\n",
       "Male       193     130      4  root,r,r,r,l,r,r,l      0  185.685714\n",
       "Male       151     154      5  root,r,r,r,r,r,r,r      0  164.853333\n",
       "Female     141     136      5  root,r,r,r,r,r,l,r      0  156.959459\n",
       "Female     154      96      5  root,r,r,r,r,r,l,r      0  156.959459\n",
       "...        ...     ...    ...                 ...    ...         ...\n",
       "Male       155      57      2  root,r,r,r,r,l,l,r      0  165.500000\n",
       "Male       187      62      1      root,l,r,l,r,l      0  191.000000\n",
       "Female     183      96      3  root,r,r,l,r,r,l,l      0  189.000000\n",
       "Male       144     108      5  root,r,r,r,r,r,l,r      0  156.959459\n",
       "Male       149     100      5  root,r,r,r,r,r,l,r      0  156.959459\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = make_predictions(val, column_types, leaves, split_conditions)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.307771159922709"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = calculate_accuracy(val, column_types, ml_task, leaves, split_conditions)\n",
    "RMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
